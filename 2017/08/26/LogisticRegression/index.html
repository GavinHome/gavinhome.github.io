<!DOCTYPE html><html lang="zh-cn"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><title>Logistic回归 | GavinHome Blog</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="[object Object]"><meta name="designer" content="minfive"><meta name="keywords" content="gavinhome 沐渊 yangxiaomin gavinhome.github.io muyuan"><meta name="description" content="风起青萍之末, 浪成微澜之间"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="http://gavinhome.github.io/2017/08/26/LogisticRegression/index.html"><link rel="icon" type="image/png" href="/img/favicon.ico" sizes="32x32"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="Gavinhome Blog"><link rel="stylesheet" href="/scss/views/page/post.css"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(/img/loader.gif)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="Gavinhome Blog" alt="Gavinhome Blog"><img src="/img/logo-text-white.png" alt="Gavinhome Blog"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/article" alt="文章" title="文章">文章</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="/img/static/2017-08-26/output_34_0.png" alt="Logistic回归"></div><header class="post__info"><h1 class="post__title">Logistic回归</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="https://www.github.com/gavinhome">gavinhome</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2017-08-26</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/机器学习/">机器学习</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-eye"></i><ul class="mark__list clearfix"><li id="busuanzi_container_page_pv" class="mark__item"><span id="busuanzi_value_page_pv"></span>次</li></ul></div></div></header><div class="post__content"><p>Logistic回归回归又称Logistic回归回归分析，是一种广义的线性回归分析模型，常用于数据挖掘，疾病自动诊断，经济预测等领域。</p><ol><li>分类问题的首选算法。</li><li>Logistic回归解决二分类问题，Softmax回归解决多分类问题。</li></ol><h2 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h2><p>$$g\left(z\right) = \frac{1}{1+e^{-z}}=h_\theta \left(x\right) =g\left ( \theta ^Tx \right )=\frac{1}{1+e^{-\theta ^T x}}$$</p><p>$${g}’\left ( x \right ) = {\left ( \frac{1}{1+e^{-x}} \right )}’=\frac{e^{-x}}{\left ( 1+e^{-x} \right )^2}=\frac{1}{1+e^{-x}}\cdot \left ( 1- \frac{1}{1+e^{-x}} \right )=g\left ( x \right )\cdot \left ( 1-g\left ( x \right ) \right )$$</p><h3 id="Logistic回归参数估计"><a href="#Logistic回归参数估计" class="headerlink" title="Logistic回归参数估计"></a>Logistic回归参数估计</h3><p>假定：<br>$$P\left ( y=1|x;\theta \right ) = h_\theta \left ( x \right )$$,<br>$$P\left ( y=0|x;\theta \right ) = 1-h_\theta \left (x \right)$$</p><p>则：<br>$$P\left(y|x;\theta\right)=\left(h_\theta\left(x\right )\right)^y\left(1-h_\theta\left(x\right)\right)^{1-y}$$</p><p>似然函数：<br>$$L\left ( \theta \right ) = p\left ( \vec{y}|X;\theta \right ) = \prod_{i = 1}^{m}p\left ( y^\left ( i \right ) \right | {x^\left ( i \right )};\theta ) = \prod_{i=1}^{m}{\left ( h_\theta \left ( x^{\left ( i \right )} \right ) \right )^{y^\left ( i \right ) }} {\left ( 1-h_\theta\left ( x^\left ( i \right ) \right ) \right )^{1-y^\left ( i \right )}}$$</p><p>取对数得到：$$l\left ( \theta \right ) = logL\left ( \theta \right ) = \sum_{i=1}^{m}y^{\left ( i \right )}logh\left ( x^\left ( i \right ) \right ) + \left ( 1-y^\left ( i \right ) \right ) log\left ( 1-h\left ( x^\left ( i \right ) \right ) \right )$$</p><p>最后，对$$\theta$$参数求偏导：</p><p>$$\frac{\partial l\left ( \theta \right )}{\partial \theta_j} = \sum_{i=1}^{m}\left ( y^{\left ( i \right ) } -g\left ( \theta^Tx^{\left ( i \right )} \right )\right )\cdot x_j^{\left ( i \right )}$$</p><h3 id="参数迭代"><a href="#参数迭代" class="headerlink" title="参数迭代"></a>参数迭代</h3><p>Logistic回归参数的学习规则：</p><p>$$\theta_j: = \theta_j + \alpha \left ( y^{\left ( i \right )} - h_\theta\left ( x^{\left ( i \right )} \right )\right )x_j^{\left ( i \right )}$$</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>$$\therefore loss\left ( y_i,\hat{y}_i \right ) = -l\left ( \theta \right )$$，其中$$y_i\in \left { 0,1 \right }$$,$$\hat{y} = \left{\begin{matrix}<br>p_i &amp; y_i=1 \<br>1-p_i &amp; y_i = 0<br>\end{matrix}\right.$$</p><p>带入推导可得最终损失函数：$$\therefore loss\left ( y_i,\hat{y}<em>i \right ) = -l\left ( \theta \right ) = - \sum</em>{i=1}^{m}ln\left [ p_i^{y_i}\left ( 1-p_i \right )^{1-y_i} \right ] = \sum_{i=1}^{m}ln\left [ y_iln\left ( 1+e^{-f_i} \right ) + \left ( 1-y_i \right )ln\left ( 1+e^{f_i} \right )\right ]$$</p><h3 id="Logistic回归的损失"><a href="#Logistic回归的损失" class="headerlink" title="Logistic回归的损失"></a>Logistic回归的损失</h3><p>$$y_i\in \left { -1,1 \right }$$</p><p>$$L\left ( \theta \right ) = \prod_{i=1}^{m}P_i^{\frac{\left ( y_i + 1 \right)}{2}}\left ( 1-P_i\right )^{\frac{-\left ( y_i-1 \right )}{2}}$$</p><p>$$loss\left ( y_i,\hat{y_i} \right )=\sum_{i=1}^{m}\left [ ln\left ( 1+e^{-y_i\cdot f_i} \right ) \right ]$$</p><h2 id="广义线性模型Generalized-Linear-Model"><a href="#广义线性模型Generalized-Linear-Model" class="headerlink" title="广义线性模型Generalized Linear Model"></a>广义线性模型Generalized Linear Model</h2><ol><li>y不再只是正太分布，而是扩大为指数族中的任一分布；</li><li>x -&gt; g(x) -&gt; y,连接函数g单调可导，例如逻辑回归中的$$g\left ( z \right ) = \frac{1}{1+e^{-z}}$$，拉伸变换$$g\left(z\right )=\frac{1}{1+e^{-\lambda z}}$$</li></ol><p><img src="https://raw.githubusercontent.com/GavinHome/MLL/master/images/GLM.png" alt="GLM" title="GLM"></p><h2 id="Softmax回归"><a href="#Softmax回归" class="headerlink" title="Softmax回归"></a>Softmax回归</h2><ol><li>K分类，第k类的参数为$$\vec{\theta_k}$$，组成二维矩阵$$\theta _{k\times n}$$</li><li>概率：$$p\left ( c=kx;\theta\right)=\frac{exp\left ( \theta_k^T x \right )}{\sum_{l=1}^{K}exp\left ( \theta_l^T x \right )}$$, 其中k=1,2,……,K</li><li>似然函数：$$ L\left ( \theta \right ) =\prod_{l=1}^{m}\prod_{k=1}^{K} p\left (c=k|x^{\left ( i \right )} ;\theta \right )^{y_k^\left ( i \right )}<br>=\prod_{l=1}^{K}\prod_{k=1}^{K}\left( exp\left ( \theta_k^T x^{\left ( l \right )} \right ) / \sum_{l=1}^{K}exp\left ( \theta^T_l x^\left ( l \right ) \right )\right )^{y_k^{\left ( i \right )}} $$</li><li>对数似然：<br>$$J_m\left ( \theta \right ) = ln L\left ( \theta \right ) = \sum_{i=1}^{m}\sum_{k=1}^{K}y_k^{\left ( i \right )}\cdot \left ( \theta^T_kx^{\left ( i \right )} - ln \sum_{l=1}^{K}exp\left ( \theta^T_l x^{\left ( i \right )} \right )\right )$$，<br>$$J\left ( \theta \right ) = \sum_{k=1}^{K}y_k\cdot \left ( \theta^T_k x - ln\sum_{l=1}^{K}exp\left ( \theta_l^Tx \right )\right )$$</li><li>随机梯度：<br>$$\frac{\partial J\left ( \theta \right )}{\partial \theta_k} = \left ( y_k - p\left ( y_k|x,\theta \right ) \right )\cdot x$$</li></ol><h2 id="鸢尾花分类"><a href="#鸢尾花分类" class="headerlink" title="鸢尾花分类"></a>鸢尾花分类</h2><h3 id="实验数据"><a href="#实验数据" class="headerlink" title="实验数据"></a>实验数据</h3><p>鸢尾花数据集是最有名的模式识别测试数据，1936年模式识别先驱Fisher在其论文“The use of multiple measurements in taxonomic problems” 使用了它。数据集包括3个鸢尾花类别，每个类别有50个样本，其中一个类别与另外两类线性可分，而另外两类不能线性可分。</p><h3 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h3><p>该数据集包括150行，每行为1个样本，每个样本共有5个字段，分别是花萼长度，花萼宽度，花瓣长度，花瓣宽度，类别。其中类别包括Iris Setosa, Iris Versicolour,Iris Virginica三类，前四个字段的单位为cm。</p><h3 id="实验代码"><a href="#实验代码" class="headerlink" title="实验代码"></a>实验代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl <span class="comment"># 设置环境变量</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 绘图专用</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">'utf8'</span>)</span><br><span class="line">mpl.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'FangSong'</span>]</span><br><span class="line">mpl.rcParams[<span class="string">'axes.unicode_minus'</span>]=<span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iris_type</span><span class="params">(s)</span>:</span></span><br><span class="line">    it = &#123;<span class="string">'Iris-setosa'</span>:<span class="number">0</span>,<span class="string">'Iris-versicolor'</span>:<span class="number">1</span>,<span class="string">'Iris-virginica'</span>:<span class="number">2</span>&#125;</span><br><span class="line">    <span class="keyword">return</span> it[s]</span><br><span class="line"></span><br><span class="line">url=<span class="string">"http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"</span></span><br><span class="line">data = pd.read_table(io.StringIO(requests.get(url).content.decode(<span class="string">'utf-8'</span>)), sep=<span class="string">" "</span>, delimiter=<span class="string">','</span>, dtype=float, converters=&#123;<span class="number">4</span>:iris_type&#125;, header=<span class="literal">None</span>,names=[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>,<span class="string">'e'</span>]).values</span><br><span class="line"><span class="comment"># print data</span></span><br><span class="line"><span class="comment"># print type(data)</span></span><br><span class="line"></span><br><span class="line">x,y = np.split(data,(<span class="number">4</span>,),axis=<span class="number">1</span>)</span><br><span class="line">x=x[:,:<span class="number">2</span>]</span><br><span class="line"><span class="comment">#print x</span></span><br><span class="line"></span><br><span class="line">logreg = LogisticRegression()</span><br><span class="line">logreg.fit(x,y.ravel())</span><br><span class="line"></span><br><span class="line">N, M = <span class="number">500</span>, <span class="number">500</span></span><br><span class="line">x1_min, x1_max = x[:,<span class="number">0</span>].min(),x[:,<span class="number">0</span>].max()</span><br><span class="line">x2_min, x2_max = x[:,<span class="number">1</span>].min(),x[:,<span class="number">1</span>].max()</span><br><span class="line">t1 = np.linspace(x1_min,x1_max,N)</span><br><span class="line">t2 = np.linspace(x2_min,x2_max,M)</span><br><span class="line"></span><br><span class="line">x1,x2 = np.meshgrid(t1, t2)</span><br><span class="line">x_test = np.stack((x1.flat,x2.flat), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">y_hat = logreg.predict(x_test)</span><br><span class="line">y_hat = y_hat.reshape(x1.shape)</span><br><span class="line">plt.pcolormesh(x1,x2,y_hat,cmap=plt.cm.prism)</span><br><span class="line">plt.scatter(x[:,<span class="number">0</span>],x[:,<span class="number">1</span>], c=y, edgecolors=<span class="string">'k'</span>,cmap=plt.cm.prism)</span><br><span class="line">plt.xlabel(<span class="string">'Sepal Length'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Sepal Width'</span>)</span><br><span class="line">plt.xlim(x1_min, x1_max)</span><br><span class="line">plt.ylim(x2_min, x2_max)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="/img/static/2017-08-26/output_34_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">y_hat = logreg.predict(x)</span><br><span class="line">y = y.reshape(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> y_hat.shape</span><br><span class="line"><span class="keyword">print</span> y.shape</span><br><span class="line">result = y_hat == y</span><br><span class="line"><span class="keyword">print</span> y_hat</span><br><span class="line"><span class="keyword">print</span> y</span><br><span class="line"><span class="keyword">print</span> result</span><br><span class="line">c=np.count_nonzero(result)</span><br><span class="line"><span class="keyword">print</span> c</span><br><span class="line"><span class="string">'Accuracy: %.2f%%'</span> % (<span class="number">100</span>*float(c)/float(len(result)))</span><br></pre></td></tr></table></figure><pre><code>&apos;Accuracy: 76.67%&apos;
</code></pre><h3 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h3><ol><li>仅用花萼长度和宽度，在150个样本中，有115个分类正确，正确率为76.67%</li><li>使用四个特征，试验后发现有144个样本分类正确，正确率为96%.</li></ol><h2 id="案例跟踪"><a href="#案例跟踪" class="headerlink" title="案例跟踪"></a>案例跟踪</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl <span class="comment"># 设置环境变量</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 绘图专用</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection  <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">'utf8'</span>)</span><br><span class="line">mpl.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'FangSong'</span>]</span><br><span class="line">mpl.rcParams[<span class="string">'axes.unicode_minus'</span>]=<span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iris_type</span><span class="params">(s)</span>:</span></span><br><span class="line">    it = &#123;<span class="string">'Iris-setosa'</span>:<span class="number">0</span>,<span class="string">'Iris-versicolor'</span>:<span class="number">1</span>,<span class="string">'Iris-virginica'</span>:<span class="number">2</span>&#125;</span><br><span class="line">    <span class="keyword">return</span> it[s]</span><br><span class="line"></span><br><span class="line">url=<span class="string">"http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"</span></span><br><span class="line">data = pd.read_table(io.StringIO(requests.get(url).content.decode(<span class="string">'utf-8'</span>)), sep=<span class="string">" "</span>, delimiter=<span class="string">','</span>, dtype=float, converters=&#123;<span class="number">4</span>:iris_type&#125;, header=<span class="literal">None</span>,names=[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>,<span class="string">'e'</span>]).values</span><br><span class="line"><span class="comment"># print data</span></span><br><span class="line"><span class="comment"># print type(data)</span></span><br><span class="line"></span><br><span class="line">x,y = np.split(data,(<span class="number">4</span>,),axis=<span class="number">1</span>)</span><br><span class="line">X=x[:,:<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">x1_min, x1_max = x[:,<span class="number">0</span>].min(),x[:,<span class="number">0</span>].max()</span><br><span class="line">x2_min, x2_max = x[:,<span class="number">1</span>].min(),x[:,<span class="number">1</span>].max()</span><br><span class="line"></span><br><span class="line">plt.scatter(x[:,<span class="number">0</span>],x[:,<span class="number">1</span>], c=y, edgecolors=<span class="string">'k'</span>,cmap=plt.cm.prism)</span><br><span class="line">plt.xlabel(<span class="string">'Sepal Length'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Sepal Width'</span>)</span><br><span class="line">plt.xlim(x1_min, x1_max)</span><br><span class="line">plt.ylim(x2_min, x2_max)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=<span class="number">1</span>)</span><br><span class="line">linreg = LogisticRegression()</span><br><span class="line">model = linreg.fit(X_train,y_train)</span><br><span class="line">y_pred = linreg.predict(X_test)</span><br><span class="line"><span class="comment"># print linreg.coef_</span></span><br><span class="line"></span><br><span class="line">result = y_pred == y_test.ravel()</span><br><span class="line"></span><br><span class="line">c=np.count_nonzero(result)</span><br></pre></td></tr></table></figure><p><img src="/img/static/2017-08-26/output_39_0.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'Accuracy: %.2f%%'</span> % (<span class="number">100</span>*float(c)/float(len(result)))</span><br></pre></td></tr></table></figure><pre><code>&apos;Accuracy: 84.21%&apos;
</code></pre><p>分析：</p><ol><li>第四节使用训练集测试，结果正确性有误</li><li>本实验分训练集和测试集，准确率为84.21%</li></ol><div class="post-announce">感谢您的阅读，本文由 <a href="http://gavinhome.github.io">Gavinhome Blog</a> 版权所有。如若转载，请注明出处：Gavinhome Blog（<a href="http://gavinhome.github.io/2017/08/26/LogisticRegression/">http://gavinhome.github.io/2017/08/26/LogisticRegression/</a>）</div><div class="post__prevs"><div class="post__prev"><a href="/2017/08/25/LinearRegression/" title="线性回归"><i class="iconfont icon-prev"></i>线性回归</a></div><div class="post__prev post__prev--right"><a href="/2018/01/27/支持向量机/" title="支持向量机（SVM）">支持向量机（SVM）<i class="iconfont icon-next"></i></a></div></div></div></article><div id="comment-container"></div></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">风起青萍之末, 浪成微澜之间</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3><ul class="block-list"><li class="block-list-item"><a class="block-list-link" href="/categories/脚本/">脚本</a><span class="block-list-count">1</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/机器学习/">机器学习</a><span class="block-list-count">4</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/hexo/">hexo</a><span class="block-list-count">1</span></li><li class="block-list-item"><a class="block-list-link" href="/categories/Python/">Python</a><span class="block-list-count">1</span></li></ul></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2019/03/31/自动压缩并拷贝数据库备份至备份机器/" title="自动压缩并拷贝数据库备份至备份机器"><div class="item__cover"><img src="/img/cover/backup.jpeg" alt="自动压缩并拷贝数据库备份至备份机器"></div><div class="item__info"><h3 class="item__title">自动压缩并拷贝数据库备份至备份机器</h3><span class="item__text">2019-03-31</span></div></a></li><li class="latest-post-item"><a href="/2019/03/29/搭建Hexo静态资源博客/" title="搭建Hexo静态资源博客"><div class="item__cover"><img src="/img/cover/two-black-flat-screen-computer-monitors.jpeg" alt="搭建Hexo静态资源博客"></div><div class="item__info"><h3 class="item__title">搭建Hexo静态资源博客</h3><span class="item__text">2019-03-29</span></div></a></li><li class="latest-post-item"><a href="/2019/01/25/matplotlib可视化数据/" title="matplotlib可视化数据"><div class="item__cover"><img src="/img/static/2017-08-12/output_14_0.png" alt="matplotlib可视化数据"></div><div class="item__info"><h3 class="item__title">matplotlib可视化数据</h3><span class="item__text">2019-01-25</span></div></a></li><li class="latest-post-item"><a href="/2018/02/08/决策树和随机森林/" title="决策树与随机森林"><div class="item__cover"><img src="/img/static/2018-01-28/figure_1.png" alt="决策树与随机森林"></div><div class="item__info"><h3 class="item__title">决策树与随机森林</h3><span class="item__text">2018-02-08</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/hexo/">hexo</a></li><li class="tag-item"><a class="tag-link" href="/tags/matplotlib/">matplotlib</a></li><li class="tag-item"><a class="tag-link" href="/tags/windows-server/">windows server</a></li><li class="tag-item"><a class="tag-link" href="/tags/数据库备份/">数据库备份</a></li><li class="tag-item"><a class="tag-link" href="/tags/机器学习/">机器学习</a></li><li class="tag-item"><a class="tag-link" href="/tags/脚本/">脚本</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text">本站点基于 Hexo 搭建的静态资源博客，主要记录工作和生活中遇到的一些有趣的事物，仅用于交流，转载请著名出处，欢迎点击右下角订阅 rss。</p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span>Xi'an, Shaanxi Province, China</span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span>yangxiaoming512@yeah.net</span></li></ul></div></div><div class="footer-top__item footer__image"><img src="/img/qrcode.png" alt="logo" title="Gavinhome Blog"></div><div class="footer-top__item"><h3 class="item__title">友情链接</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="https://github.com/Mrminfive/hexo-theme-skapp" title="hexo-theme-skapp" target="_blank">hexo-theme-skapp</a></li></ul></div></div><div class="footer-top__item"><h3 class="item__title">构建工具</h3><div class="item__content"><ul class="footer-top__list"><li class="list-item"><a href="https://hexo.io/" title="Blog Framework" target="_blank">Hexo</a></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2017 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>.</p><ul class="footer__social-network clearfix"><li class="social-network__item"><a href="https://github.com/GavinHome" target="_blank" title="github"><i class="iconfont icon-github"></i></a></li><li class="social-network__item"><a href="https://www.zhihu.com/people/jingliushui/activities" target="_blank" title="zhihu"><i class="iconfont icon-zhihu"></i></a></li><li class="social-network__item"><a href="https://weibo.com/u/6858743095" target="_blank" title="weibo"><i class="iconfont icon-weibo"></i></a></li><li class="social-network__item"><a href="mailto:yangxiaoming512@yeah.net" target="_blank" title="email"><i class="iconfont icon-email"></i></a></li><li class="social-network__item"><a href="/atom.xml" target="_blank" title="rss"><i class="iconfont icon-rss"></i></a></li></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script src="/js/md5.min.js"></script><script>var tags=["机器学习"],gitalk=new Gitalk({clientID:"9e9190730c0096e92ada",clientSecret:"241f5a5a27c8fed4af6f0e826b55df5f027724c2",repo:"gavinhome.github.io",owner:"GavinHome",admin:["GavinHome"],labels:tags,id:new Date(1503716226e3).getTime()>new Date("2010-02-15").getTime()?md5(location.href):location.href});gitalk.render("comment-container")</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
            });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
                for (i=0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
                }
            });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>